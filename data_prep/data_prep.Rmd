---
title: "gds_podcast_text"
author: "Kurtis Smith"
date: "12/07/2021"
output: html_document
---

```{r setup, include=FALSE}

# Load packages and download data

library(tidyverse)
library(tidytext)
library(feather)

txt <- readxl::read_xlsx(path = 'C:/Users/Kurtissmith/Documents/R/projects/gds_podcast/data_prep/gds_podcast.xlsx',
                         sheet = 'text',
                         col_names = TRUE, 
                         trim_ws = TRUE) %>% 
                  mutate(episode_number = as.integer(episode_number), 
                         transcript = str_replace_all(transcript, "’", ""), 
                         transcript = str_replace_all(transcript, "'", "")) %>%  # Was stopping stop words removal in full
                  select(-floor_date_released)

characters <- readxl::read_xlsx(path = 'C:/Users/Kurtissmith/Documents/R/projects/gds_podcast/data_prep/gds_podcast.xlsx',
                                sheet = 'characters',
                                col_names = TRUE, 
                                trim_ws = TRUE) %>% 
              unnest_tokens("word", "character", token = "words") # Cleans name, helps removal from data

negation_words <- readxl::read_xlsx(path = 'C:/Users/Kurtissmith/Documents/R/projects/gds_podcast/data_prep/gds_podcast.xlsx',
                                sheet = 'negation',
                                col_names = TRUE, 
                                trim_ws = TRUE) %>% 
              unnest_tokens("word", "negation", token = "words") 

# Stop words

custom_stop_words <- data.frame(
  word = c("yeah", "nah", "aww", "err", "um", "wed"), 
  lexicon = c("custom")
)

all_stop_words <- rbind(stop_words, custom_stop_words)

# Tidied data

tidy_gds <- txt %>%
  tidytext::unnest_tokens("word", "transcript", token = "words") %>%
  left_join(negation_words, by = "word", keep = TRUE) %>%
  left_join(get_sentiments("bing"), by = c("word.x" = "word")) %>%
  mutate(sentiment = case_when(  # Reversing sentiment for negation words
            lag(!is.na(word.y), n = 1L) & sentiment == "positive" ~ "negative", 
            lag(!is.na(word.y), n = 1L) & sentiment == "negative" ~ "positive", 
            TRUE ~ sentiment)) %>%
  select(-word.y, 
         word = word.x) %>%
  anti_join(all_stop_words, by = "word") %>% 
  anti_join(characters, by = "word")

# Complete stemmed words

to_stem_words <- readxl::read_xlsx(path = 'C:/Users/Kurtissmith/Documents/R/projects/gds_podcast/data_prep/gds_podcast.xlsx',
                         sheet = 'stem',
                         col_names = TRUE, 
                         trim_ws = TRUE)

```

Adjusted Sentiment Summary

```{r}

# Using negation words reverse score sentiment

adj_sentiment_summary <- tidy_gds %>%
  group_by(episode_number, episode_name) %>% 
  mutate(
    positive = sum(if_else(sentiment == "positive", true = 1, false = 0, missing = 0)), 
    negative = sum(if_else(sentiment == "negative", true = 1, false = 0, missing = 0))
  ) %>% 
  group_by(episode_number, episode_name, positive, negative) %>% 
  summarise(word_count = n()) %>% 
  ungroup() %>% 
  mutate(
    sentiment_difference = positive - negative,
    positive_ratio = round((positive / word_count) * 100, digits = 2), 
    negative_ratio = round((negative / word_count) * 100, digits = 2),
    overall_sentiment = if_else(sentiment_difference > 0,
                                true = "Positive", 
                                false = "Negative")
  ) %>% 
  select(episode_number, episode_name, word_count, everything())

write_feather(adj_sentiment_summary, "C:/Users/Kurtissmith/Documents/R/projects/gds_podcast/df_summary.feather")

```

Words Characteristic of Episodes

```{r}

characteristics <- tidy_gds %>%
  mutate(word = ifelse(word %in% to_stem_words$word, 
                       yes = to_stem_words$word_stemmed, 
                       no = word)) %>% 
  count(episode_number, episode_name, word, sort = TRUE) %>% 
  bind_tf_idf(word, episode_name, n) %>%
  arrange(episode_number, desc(tf_idf)) %>%
  group_by(episode_name) %>% 
  slice_max(order_by = tf_idf, n = 5) 

characteristics %>% filter(episode_number == 36) # Check top 5 characteristics for potential stems

write_feather(characteristics, "C:/Users/Kurtissmith/Documents/R/projects/gds_podcast/df_characteristics.feather")

```

Sentiment Change

```{r}

sentiment_change <- tidy_gds %>% 
  mutate(sentiment = ifelse(is.na(sentiment), yes = 0, no = sentiment),
         sentiment = str_to_sentence(sentiment))

write_feather(sentiment_change, "C:/Users/Kurtissmith/Documents/R/projects/gds_podcast/df_sentiment_change.feather")

rm(list = ls())

```


Possible Improvements

1. Done - Word stemming
2. Add floor released date for exploratory questions (adding that statistical elemnet)
3. Build a language model > train > and then given a topic tell it to spit something out
4. Entity detection > pick out specific gov departments, costs, dates, eligability criteria

```{r}
# Exploratory Analysis point 2

library(tidyverse)
library(tidytext)
library(feather)

txt2 <- readxl::read_xlsx(path = 'D:/R/gds_podcast/data_prep/gds_podcast.xlsx',
                         sheet = 'text',
                         col_names = TRUE, 
                         trim_ws = TRUE) %>% 
                  mutate(episode_number = as.integer(episode_number), 
                         transcript = str_replace_all(transcript, "’", "'")) %>%  # Was stopping stop words removal in full
                  select(-floor_date_released)

```




















